{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data Analysis (3803ICT_3251/3030ICT_3251) in week 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Course structure\n",
    "- 10 lectures (2 hours each)\n",
    "- 10 practical lab sessions (2 hours each)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessment\n",
    "- 10 weekly workshops are graded: 20% (2% each). Each one has 1 week to complete (due to next-week Sunday 23:59)\n",
    "- 1 Assignment: 35%, due Sunday, week 11 (23:59). Group submission (2 persons/group). Similar content to the labs\n",
    "- 1 final exam: 45%. 2 hours examination\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time and location\n",
    "- The lecture is: Mon 8:00 – 9:50 with location: online.\n",
    "- The workshop varies: \n",
    "    - 3803ICT: GC campus: Mon 11AM-12:50AM or 2PM - 3:50PM at G23_2.27. Online: Mon 2PM – 3:50PM\n",
    "    - 3030ICT: GC campus: Mon 4PM - 5:50PM G31_3.14 or Tues 14:00AM – 15:50PM G23_2.22. NA campus: Mon 2PM-3:50PM at N79_4.10. Online: Mon 2PM - 3:50PM\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Science, Applications, and Tools\n",
    "**Data Science**. Data Science is an interdisciplinary field that combines statistics, mathematics, computer science, and domain expertise to extract meaningful insights from structured and unstructured data. It involves various stages, including data collection, preprocessing, analysis, visualization, and interpretation. The goal of data science is to uncover patterns, trends, and correlations that can drive decision-making and automation.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applications**. Data Science is widely used across industries to solve real-world problems. Some key applications include:\n",
    "- Business & Finance: Fraud detection, customer segmentation, risk assessment, stock market prediction.\n",
    "- Healthcare: Disease prediction, medical image analysis, personalized medicine.\n",
    "- Technology & AI: Natural Language Processing (NLP), speech recognition, image recognition.\n",
    "- Environmental & Sustainability: Climate modeling, energy optimization, disaster response.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tools**. Data Science relies on a variety of tools and technologies to process and analyze data. Some popular tools include:\n",
    "- Programming Languages: Python (NumPy, Pandas, Scikit-learn, TensorFlow, PyTorch), R (ggplot2, dplyr, caret), SQL (PostgreSQL, MySQL)\n",
    "- Data Processing & Storage. Hadoop, Spark for big data processing. SQL & NoSQL databases (MongoDB, PostgreSQL)\n",
    "- Data Visualization. Matplotlib, Seaborn (Python). Tableau, Power BI\n",
    "- Machine Learning & AI. Scikit-learn, TensorFlow, PyTorch. XGBoost, LightGBM for gradient boosting\n",
    "- Cloud & Deployment. AWS, Google Cloud, Microsoft Azure. Docker, Kubernetes for model deployment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- Install python\n",
    "- Install Anaconda\n",
    "- Install Jupyter Notebook\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Basics\n",
    "numpy, scipy, pandas, scikit learn, ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas \n",
    "Pandas is a powerful open-source Python library used for data manipulation and analysis. It provides data structures and functions needed to efficiently manipulate large datasets."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "January     5000\n",
      "February    7000\n",
      "March       6500\n",
      "April       8000\n",
      "May         7200\n",
      "Name: Monthly Sales, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creating a more realistic Pandas Series example\n",
    "sales_data = {\n",
    "    'January': 5000,\n",
    "    'February': 7000,\n",
    "    'March': 6500,\n",
    "    'April': 8000,\n",
    "    'May': 7200\n",
    "}\n",
    "\n",
    "# Creating the Series\n",
    "sales_series = pd.Series(sales_data, name=\"Monthly Sales\")\n",
    "\n",
    "# print the Series\n",
    "print(sales_series)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Month  Sales  Expenses  Profit\n",
      "0   January   5000      3000    2000\n",
      "1  February   7000      4000    3000\n",
      "2     March   6500      3200    3300\n",
      "3     April   8000      4500    3500\n",
      "4       May   7200      3800    3400\n"
     ]
    }
   ],
   "source": [
    "sales_df = pd.DataFrame({\n",
    "    'Month': ['January', 'February', 'March', 'April', 'May'],\n",
    "    'Sales': [5000, 7000, 6500, 8000, 7200],\n",
    "    'Expenses': [3000, 4000, 3200, 4500, 3800],  # Added expenses column\n",
    "    'Profit': [2000, 3000, 3300, 3500, 3400]  # Calculated profit\n",
    "})\n",
    "\n",
    "# print the DataFrame\n",
    "print(sales_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Sales  Expenses  Profit\n",
      "Month                            \n",
      "April     16200      9200    7000\n",
      "February  14500      8200    6300\n",
      "January   10200      6100    4100\n",
      "March     13200      6500    6700\n",
      "May       14500      7700    6800\n"
     ]
    }
   ],
   "source": [
    "# Creating a DataFrame with multiple entries per month to demonstrate the effectiveness of groupby\n",
    "sales_data_expanded = pd.DataFrame({\n",
    "    'Month': ['January', 'January', 'February', 'February', 'March', 'March', 'April', 'April', 'May', 'May'],\n",
    "    'Sales': [5000, 5200, 7000, 7500, 6500, 6700, 8000, 8200, 7200, 7300],\n",
    "    'Expenses': [3000, 3100, 4000, 4200, 3200, 3300, 4500, 4700, 3800, 3900],\n",
    "    'Profit': [2000, 2100, 3000, 3300, 3300, 3400, 3500, 3500, 3400, 3400]\n",
    "})\n",
    "\n",
    "# Grouping by 'Month' and summing up the values\n",
    "grouped_sales_expanded_df = sales_data_expanded.groupby('Month').sum()\n",
    "\n",
    "# print the grouped DataFrame\n",
    "print(grouped_sales_expanded_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Month  Sales  Expenses  Profit\n",
      "0   January   5000      3000    2000\n",
      "1   January   5200      3100    2100\n",
      "2  February   7000      4000    3000\n",
      "3  February   7500      4200    3300\n",
      "4     March   6500      3200    3300\n",
      "5     March   6700      3300    3400\n",
      "6     April   8000      4500    3500\n",
      "7     April   8200      4700    3500\n",
      "8       May   7200      3800    3400\n",
      "9       May   7300      3900    3400\n"
     ]
    }
   ],
   "source": [
    "# Saving the expanded sales DataFrame to a CSV file\n",
    "csv_filename = \"../data/wk1_sales_data.csv\"\n",
    "sales_data_expanded.to_csv(csv_filename, index=False)\n",
    "\n",
    "# One-liner to read the DataFrame from the saved CSV file\n",
    "df_from_csv = pd.read_csv(csv_filename)\n",
    "\n",
    "# print the DataFrame read from the CSV file\n",
    "print(df_from_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Month  Sales  Expenses  Profit\n",
      "0   January   5000      3000    2000\n",
      "1   January   5200      3100    2100\n",
      "2  February   7000      4000    3000\n",
      "3  February   7500      4200    3300\n",
      "4     March   6500      3200    3300\n",
      "5     March   6700      3300    3400\n",
      "6     April   8000      4500    3500\n",
      "7     April   8200      4700    3500\n",
      "8       May   7200      3800    3400\n",
      "9       May   7300      3900    3400\n"
     ]
    }
   ],
   "source": [
    "# Saving the expanded sales DataFrame to a excel file\n",
    "excel_filename = \"../data/wk1_sales_data.xlsx\"\n",
    "sales_data_expanded.to_excel(excel_filename, index=False)\n",
    "\n",
    "# One-liner to read the DataFrame from the saved excel file\n",
    "df_from_excel = pd.read_excel(excel_filename)\n",
    "\n",
    "# print the DataFrame read from the excel file\n",
    "print(df_from_excel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Month  Sales  Expenses  Profit\n",
      "0   January   5000      3000    2000\n",
      "1   January   5200      3100    2100\n",
      "2  February   7000      4000    3000\n",
      "3  February   7500      4200    3300\n",
      "4     March   6500      3200    3300\n",
      "5     March   6700      3300    3400\n",
      "6     April   8000      4500    3500\n",
      "7     April   8200      4700    3500\n",
      "8       May   7200      3800    3400\n",
      "9       May   7300      3900    3400\n"
     ]
    }
   ],
   "source": [
    "# Saving the expanded sales DataFrame to an HTML file\n",
    "html_filename = \"../data/wk1_sales_data.html\"\n",
    "sales_data_expanded.to_html(html_filename, index=False)\n",
    "\n",
    "# read the HTML file into a DataFrame\n",
    "df_from_html = pd.read_html(html_filename)[0]\n",
    "\n",
    "# print the DataFrame read from the HTML file\n",
    "print(df_from_html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "(also known as data cleansing or data scrubbing) is the process of identifying, correcting, or removing errors, inconsistencies, and inaccuracies in a dataset. It ensures that data is accurate, complete, and ready for analysis.\n",
    "\n",
    "### Why is data cleaning important?\n",
    "- Improves Data Quality – Ensures reliable and accurate insights.\n",
    "- Reduces Errors – Prevents incorrect conclusions due to faulty data.\n",
    "- Enhances Model Performance – Essential for machine learning and statistical analysis.\n",
    "- Ensures Consistency – Standardizes data formats and structures.\n",
    "- Removes Redundancies – Eliminates duplicate or irrelevant data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Data:\n",
      "      Name     Age           City   Salary\n",
      "0   Alice       25       New York  50000.0\n",
      "1      BOB  thirty    Los angeles  60000.0\n",
      "2  Charlie      35       CHICAGO   70000.0\n",
      "3    Alice      26       New York      NaN\n",
      "4      BOB    None    los angeles  62000.0\n",
      "5    David      40  San Francisco  80000.0\n",
      "6     None      29        Chicago  75000.0 \n",
      "\n",
      "After standardizing text format:\n",
      "      Name     Age           City   Salary\n",
      "0    Alice      25       New York  50000.0\n",
      "1      Bob  thirty    Los Angeles  60000.0\n",
      "2  Charlie      35        Chicago  70000.0\n",
      "3    Alice      26       New York      NaN\n",
      "4      Bob    None    Los Angeles  62000.0\n",
      "5    David      40  San Francisco  80000.0\n",
      "6     None      29        Chicago  75000.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creating a raw dataset with various data quality issues\n",
    "raw_data = {\n",
    "    'Name': ['Alice ', 'BOB', 'Charlie', 'Alice', 'BOB', 'David', None], # the first Alice has a trailing space\n",
    "    'Age': ['25', 'thirty', '35', '26', None, '40', '29'],\n",
    "    'City': ['New York', 'Los angeles', 'CHICAGO ', ' New York', 'los angeles', 'San Francisco', 'Chicago'], # the first chicago has a trailing space\n",
    "    'Salary': [50000, 60000, 70000, None, 62000, 80000, 75000]\n",
    "}\n",
    "\n",
    "# Converting raw data into a Pandas DataFrame\n",
    "df = pd.DataFrame(raw_data)\n",
    "df_origin = df.copy()\n",
    "\n",
    "# Displaying the raw data before cleaning\n",
    "print(\"Raw Data:\")\n",
    "print(df, \"\\n\")\n",
    "\n",
    "# Data Cleaning Steps\n",
    "\n",
    "# 1. Standardizing Text Format (Removing extra spaces and making text lowercase)\n",
    "df['Name'] = df['Name'].str.strip().str.title()\n",
    "df['City'] = df['City'].str.strip().str.title()\n",
    "\n",
    "print(f\"After standardizing text format:\\n{df}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before handling missing values:\n",
      "      Name     Age           City   Salary\n",
      "0   Alice       25       New York  50000.0\n",
      "1      BOB  thirty    Los angeles  60000.0\n",
      "2  Charlie      35       CHICAGO   70000.0\n",
      "3    Alice      26       New York      NaN\n",
      "4      BOB    None    los angeles  62000.0\n",
      "5    David      40  San Francisco  80000.0\n",
      "6     None      29        Chicago  75000.0\n",
      "\n",
      "After handling missing values:\n",
      "      Name   Age           City   Salary\n",
      "0    Alice  25.0       New York  50000.0\n",
      "1      Bob   NaN    Los Angeles  60000.0\n",
      "2  Charlie  35.0        Chicago  70000.0\n",
      "3    Alice  26.0       New York  66000.0\n",
      "4      Bob   NaN    Los Angeles  62000.0\n",
      "5    David  40.0  San Francisco  80000.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Handling Missing Values\n",
    "df['Age'] = pd.to_numeric(df['Age'], errors='coerce')  # Convert age to numeric, setting errors as NaN\n",
    "# Replace missing salary with mean salary\n",
    "df['Salary'] = df['Salary'].fillna(df['Salary'].mean())  \n",
    "df.dropna(subset=['Name'], inplace=True)  # Remove rows where Name is missing\n",
    "\n",
    "print(f\"Before handling missing values:\\n{df_origin}\\n\")\n",
    "print(f\"After handling missing values:\\n{df}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing duplicates:\n",
      "      Name     Age           City   Salary\n",
      "0   Alice       25       New York  50000.0\n",
      "1      BOB  thirty    Los angeles  60000.0\n",
      "2  Charlie      35       CHICAGO   70000.0\n",
      "3    Alice      26       New York      NaN\n",
      "4      BOB    None    los angeles  62000.0\n",
      "5    David      40  San Francisco  80000.0\n",
      "6     None      29        Chicago  75000.0\n",
      "\n",
      "After removing duplicates:\n",
      "      Name   Age           City   Salary\n",
      "0    Alice  25.0       New York  50000.0\n",
      "1      Bob   NaN    Los Angeles  60000.0\n",
      "2  Charlie  35.0        Chicago  70000.0\n",
      "3    Alice  26.0       New York  66000.0\n",
      "4      Bob   NaN    Los Angeles  62000.0\n",
      "5    David  40.0  San Francisco  80000.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Removing Duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "print(f\"Before removing duplicates:\\n{df_origin}\\n\")\n",
    "print(f\"After removing duplicates:\\n{df}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ict",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "44617bf805217a4d1f6476c76f52c8cefefd7b6ad988450751d22bcf4ef9982c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
